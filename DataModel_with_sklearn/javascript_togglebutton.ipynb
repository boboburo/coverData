{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script>\n",
    "function code_toggle() {\n",
    "     var that = this;\n",
    "     function scrollBack() {\n",
    "     setTimeout(function () {\n",
    "                window.scrollTo(0, $(that).offset().top);\n",
    "        }, 500);\n",
    "    }\n",
    "    if (code_shown){\n",
    "        $('div.input').hide('500');\n",
    "        $('.toggleButton').val('Show Code');\n",
    "    } else {\n",
    "        $('div.input').show('500');\n",
    "        $('.toggleButton').val('Hide Code');\n",
    "    }\n",
    "    scrollBack();\n",
    "    code_shown = !code_shown;\n",
    "}\n",
    "\n",
    "$( document ).ready(function(){\n",
    "    code_shown=false;\n",
    "    $('div.input').hide();\n",
    "    $('.toggleButton').on('click', code_toggle);\n",
    "});\n",
    "</script>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<input type=\"submit\" class=\"toggleButton\" value=\"Show Code\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Determine what platform and the path to data\n",
    "import platform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Predetermine the column types, saves on any transformtions later on. \n",
    "#Currently pd.Categorical is not a valid dtype so they come in as objects. Ned to convert\n",
    "colTypes = {'Elevation':np.float64,'Aspect':np.float64,'Slope':np.float64,'HD.Hydro':np.float64,'VD.Hyrdro': np.float64,\n",
    "            'HD.Road': np.float64, 'HS.9am':np.float64,'HS.noon':np.float64,'HS.3pm':np.float64,\n",
    "            'wildernessArea':pd.Categorical,'soilType':pd.Categorical,'climaticZone':pd.Categorical,\n",
    "            'geologicZone':pd.Categorical,'coverType':pd.Categorical} \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if platform.system()  == \"Windows\":\n",
    "     pathToReadData =  \"C:\\\\Users\\\\IBM_ADMIN\\\\Desktop\\\\OneDrive\\\\PublicData\\\\AM\\\\v2\\\\\"\n",
    "     pathToWriteData = \"C:\\\\Users\\\\IBM_ADMIN\\\\Desktop\\\\OneDrive\\\\PublicData\\\\AM\\\\v3\\\\\"\n",
    "elif platform.system() == \"Darwin\":\n",
    "     pathToReadData = \"/Users/briancarter1/Desktop/OneDrive/PublicData/AM/v2/\"\n",
    "     pathToWriteData = \"/Users/briancarter1/Desktop/OneDrive/PublicData/AM/v3/\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<input type=\"submit\" class=\"toggleButton\" value=\"Show Code\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>HD.Hydro</th>\n",
       "      <th>VD.Hydro</th>\n",
       "      <th>HD.Road</th>\n",
       "      <th>HD.Fire</th>\n",
       "      <th>HS.9am</th>\n",
       "      <th>HS.noon</th>\n",
       "      <th>HS.3pm</th>\n",
       "      <th>wildernessArea</th>\n",
       "      <th>soilType</th>\n",
       "      <th>climaticZone</th>\n",
       "      <th>geologicZone</th>\n",
       "      <th>coverType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3391</td>\n",
       "      <td>209</td>\n",
       "      <td>12</td>\n",
       "      <td>558</td>\n",
       "      <td>174</td>\n",
       "      <td>3306</td>\n",
       "      <td>211</td>\n",
       "      <td>251</td>\n",
       "      <td>173</td>\n",
       "      <td>552</td>\n",
       "      <td>ComanchePeak</td>\n",
       "      <td>Bross</td>\n",
       "      <td>alpine</td>\n",
       "      <td>igneous and metamorphic</td>\n",
       "      <td>1.SpruceFir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3374</td>\n",
       "      <td>199</td>\n",
       "      <td>17</td>\n",
       "      <td>499</td>\n",
       "      <td>168</td>\n",
       "      <td>3276</td>\n",
       "      <td>212</td>\n",
       "      <td>252</td>\n",
       "      <td>170</td>\n",
       "      <td>576</td>\n",
       "      <td>ComanchePeak</td>\n",
       "      <td>Bross</td>\n",
       "      <td>alpine</td>\n",
       "      <td>igneous and metamorphic</td>\n",
       "      <td>1.SpruceFir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3366</td>\n",
       "      <td>197</td>\n",
       "      <td>17</td>\n",
       "      <td>484</td>\n",
       "      <td>160</td>\n",
       "      <td>3252</td>\n",
       "      <td>213</td>\n",
       "      <td>252</td>\n",
       "      <td>168</td>\n",
       "      <td>600</td>\n",
       "      <td>ComanchePeak</td>\n",
       "      <td>Bross</td>\n",
       "      <td>alpine</td>\n",
       "      <td>igneous and metamorphic</td>\n",
       "      <td>1.SpruceFir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3357</td>\n",
       "      <td>196</td>\n",
       "      <td>16</td>\n",
       "      <td>469</td>\n",
       "      <td>151</td>\n",
       "      <td>3228</td>\n",
       "      <td>214</td>\n",
       "      <td>252</td>\n",
       "      <td>167</td>\n",
       "      <td>624</td>\n",
       "      <td>ComanchePeak</td>\n",
       "      <td>Bross</td>\n",
       "      <td>alpine</td>\n",
       "      <td>igneous and metamorphic</td>\n",
       "      <td>1.SpruceFir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3346</td>\n",
       "      <td>206</td>\n",
       "      <td>17</td>\n",
       "      <td>426</td>\n",
       "      <td>140</td>\n",
       "      <td>3223</td>\n",
       "      <td>207</td>\n",
       "      <td>253</td>\n",
       "      <td>177</td>\n",
       "      <td>633</td>\n",
       "      <td>ComanchePeak</td>\n",
       "      <td>Bross</td>\n",
       "      <td>alpine</td>\n",
       "      <td>igneous and metamorphic</td>\n",
       "      <td>1.SpruceFir</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation  Aspect  Slope  HD.Hydro  VD.Hydro  HD.Road  HD.Fire  HS.9am  \\\n",
       "0       3391     209     12       558       174     3306      211     251   \n",
       "1       3374     199     17       499       168     3276      212     252   \n",
       "2       3366     197     17       484       160     3252      213     252   \n",
       "3       3357     196     16       469       151     3228      214     252   \n",
       "4       3346     206     17       426       140     3223      207     253   \n",
       "\n",
       "   HS.noon  HS.3pm wildernessArea soilType climaticZone  \\\n",
       "0      173     552   ComanchePeak    Bross       alpine   \n",
       "1      170     576   ComanchePeak    Bross       alpine   \n",
       "2      168     600   ComanchePeak    Bross       alpine   \n",
       "3      167     624   ComanchePeak    Bross       alpine   \n",
       "4      177     633   ComanchePeak    Bross       alpine   \n",
       "\n",
       "              geologicZone    coverType  \n",
       "0  igneous and metamorphic  1.SpruceFir  \n",
       "1  igneous and metamorphic  1.SpruceFir  \n",
       "2  igneous and metamorphic  1.SpruceFir  \n",
       "3  igneous and metamorphic  1.SpruceFir  \n",
       "4  igneous and metamorphic  1.SpruceFir  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read in the data without binary encoding, 15 original columns \n",
    "import pandas as pd\n",
    "coverData = pd.read_csv(pathToReadData+\"covtype15.csv\",dtype=colTypes )\n",
    "coverData.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat_columns = ['wildernessArea','soilType','climaticZone','geologicZone']\n",
    "wilderness = list(coverData['wildernessArea'].unique())\n",
    "soil = list(coverData['soilType'].unique())\n",
    "climaticZone = list(coverData['climaticZone'].unique())\n",
    "geo = list(coverData['geologicZone'].unique())\n",
    "cover = list(coverData['coverType'].unique())\n",
    "\n",
    "coverData['wildernessArea'] = pd.Categorical(coverData['wildernessArea'], categories=wilderness)\n",
    "coverData['soilType'] = pd.Categorical(coverData['soilType'], categories=soil)\n",
    "coverData['climaticZone'] = pd.Categorical(coverData['climaticZone'], categories=climaticZone)\n",
    "coverData['geologicZone'] = pd.Categorical(coverData['geologicZone'], categories=geo)\n",
    "coverData['coverType'] = pd.Categorical(coverData['coverType'], categories=cover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import sklearn.cross_validation as cv\n",
    "\n",
    "#X = coverData.ix[:, coverData.columns != 'coverType']\n",
    "# .ix makes no data.frame categorical variables are reset to objects as not valid dtype\n",
    "\n",
    "\n",
    "#Used later\n",
    "targetLabels=['1.Spruce','2.Lodge','3.Ponder','4.Cotton','5.Aspen','6.Douglas','7.Krymmholz']\n",
    "targetWeights={0 : 0.365, 1 : 0.498, 2 :0.062, 3 : 0.005, 4 : 0.016, 5 : 0.03, 6: 0.035}\n",
    "\n",
    "X = coverData.drop('coverType', axis=1)\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(coverData['coverType'])\n",
    "y=le.transform(coverData['coverType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.cross_validation as cv\n",
    "X_train, X_test, y_train, y_test = cv.train_test_split(X,y,test_size=0.9,random_state=79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "#from sklearn.svm import SVC\n",
    "#from sklearn import neighbors\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "#from sklearn.svm import SVC\n",
    "#from sklearn import neighbors\n",
    "\n",
    "CLASSIFIERS = [make_pipeline(CategoricalTransformer(), StandardScaler(),\n",
    "                             tree.DecisionTreeClassifier(criterion='gini',max_depth=10,min_samples_split=20)),\n",
    "               \n",
    "               make_pipeline(CategoricalTransformer(), StandardScaler(),\n",
    "                             tree.DecisionTreeClassifier(criterion='gini',max_depth=10,min_samples_split=20,\n",
    "                                                         class_weight=targetWeights)),\n",
    "               \n",
    "               make_pipeline(CategoricalTransformer(), StandardScaler(),\n",
    "                             tree.DecisionTreeClassifier(criterion='gini',max_depth=10,min_samples_split=20)),\n",
    "              ]\n",
    "\n",
    "MODELNAMES =  ['Tree1','WeightTarget','Tree3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "targetWeights={0 : 0, 1 : 0, 2 : 2, 3 : 30 , 4 :  8, 5 : 4 , 6: 4}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<input type=\"submit\" class=\"toggleButton\" value=\"Show Code\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  2, 30,  8,  4,  4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#n_samples / (n_classes * np.bincount(y))\n",
    "len(y_test) / (len(targetLabels)*np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_samples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-3b32c11c5d2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mn_samples\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'n_samples' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "\n",
    "#Lists to hold results\n",
    "RESULTS = []\n",
    "CONFUSIONMATRIX = []\n",
    "CLASSIFICATIONREPORT = []\n",
    "scores = ['precision_macro','recall_macro','f1_macro']\n",
    "\n",
    "for pipe,model_name in zip(CLASSIFIERS, MODELNAMES):\n",
    "    \n",
    "    #Fit the model \n",
    "    pipe.fit(X_train, y_train)\n",
    "    \n",
    "    #Cross validation 5 k-fold get accurate estatimate of the training scores. \n",
    "    train_scores = {score: cv.cross_val_score(pipe,X_train,y_train,cv=5,scoring=score) for score in scores}\n",
    "    \n",
    "    #Save the train scores in RESULTS\n",
    "    results_dict = {'Model': model_name ,           \n",
    "                    'precision_macro' : round(train_scores['precision_macro'].mean(),3),\n",
    "                    'recall_macro' :    round(train_scores['recall_macro'].mean(),3),\n",
    "                    'f1-score' :  round(train_scores['f1_macro'].mean(),3)\n",
    "                   }\n",
    "    \n",
    "    RESULTS.append(dict(results_dict))\n",
    "    \n",
    "    \n",
    "    #Create Train prediction for calculating Decision Report and Confusion Matrix. \n",
    "    y_train_pred = pipe.predict(X_train)\n",
    "    #y_test_pred = pipe.predict(X_test)\n",
    "    \n",
    "    # Create measures based on confusion matrix\n",
    "    cm = confusion_matrix(y_train, y_train_pred)\n",
    "    CONFUSIONMATRIX.append(cm)\n",
    "    \n",
    "    classreport = classification_report(y_train, y_train_pred,target_names=targetLabels)\n",
    "    CLASSIFICATIONREPORT.append(classreport)\n",
    "\n",
    "\n",
    "print(pd.DataFrame(RESULTS))\n",
    "multiConfusion(CONFUSIONMATRIX,MODELNAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from sklearn.pipeline import TransformerMixin\n",
    "\n",
    "class CategoricalTransformer(TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None, *args, **kwargs):\n",
    "        self.columns_ = X.columns\n",
    "        self.cat_columns_ = X.select_dtypes(include=['category']).columns\n",
    "        self.non_cat_columns_ = X.columns.drop(self.cat_columns_)\n",
    "\n",
    "        self.cat_map_ = {col: X[col].cat.categories\n",
    "                         for col in self.cat_columns_}\n",
    "        self.ordered_ = {col: X[col].cat.ordered\n",
    "                         for col in self.cat_columns_}\n",
    "\n",
    "        self.dummy_columns_ = {col: [\"_\".join([col, v])\n",
    "                                     for v in self.cat_map_[col]]\n",
    "                               for col in self.cat_columns_}\n",
    "        self.transformed_columns_ = pd.Index(\n",
    "            self.non_cat_columns_.tolist() +\n",
    "            list(chain.from_iterable(self.dummy_columns_[k]\n",
    "                                     for k in self.cat_columns_))\n",
    "        )\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, *args, **kwargs):\n",
    "        return (pd.get_dummies(X)\n",
    "                  .reindex(columns=self.transformed_columns_)\n",
    "                  .fillna(0))\n",
    "\n",
    "    def inverse_transform(self, X):\n",
    "        X = np.asarray(X)\n",
    "        series = []\n",
    "        non_cat_cols = (self.transformed_columns_\n",
    "                            .get_indexer(self.non_cat_columns_))\n",
    "        non_cat = pd.DataFrame(X[:, non_cat_cols],\n",
    "                               columns=self.non_cat_columns_)\n",
    "        for col, cat_cols in self.dummy_columns_.items():\n",
    "            locs = self.transformed_columns_.get_indexer(cat_cols)\n",
    "            codes = X[:, locs].argmax(1)\n",
    "            cats = pd.Categorical.from_codes(codes, self.cat_map_[col],\n",
    "                                             ordered=self.ordered_[col])\n",
    "            series.append(pd.Series(cats, name=col))\n",
    "        # concats sorts, we want the original order\n",
    "        df = (pd.concat([non_cat] + series, axis=1)\n",
    "                .reindex(columns=self.columns_))\n",
    "        return df\n",
    "\n",
    "self = CategoricalTransformer()  # for testing later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briancarter1/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def multiConfusion(CM,MN,cmap=plt.cm.Blues):\n",
    "    numberPlots = len(CM)\n",
    "    fig, axs = plt.subplots(1,numberPlots, figsize=(18,4), facecolor='w', edgecolor='k')\n",
    "    fig.suptitle(\"Confusion Matrices \\n Normalized by Class Size\", fontsize=14,fontweight='bold') \n",
    "    \n",
    "    axs = axs.ravel()\n",
    "    \n",
    "    for c,m,i in zip(CM,MN,range(len(MN))) :\n",
    "        cm_normalized = c.astype('float') / c.sum(axis=1)[:, np.newaxis]\n",
    "        axs[i].imshow(cm_normalized, interpolation='nearest', cmap=cmap)\n",
    "        axs[i].set_title(m)\n",
    "        tick_marks = np.arange(len(targetLabels)+1)\n",
    "        axs[i].set_xticklabels(tick_marks, rotation=90)\n",
    "        axs[i].set_yticklabels(tick_marks)\n",
    "        axs[i].set_ylabel('True label')\n",
    "        axs[i].set_xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
